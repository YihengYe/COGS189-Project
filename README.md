# COGS189-Project
This is the project repository for  COGS189 project Spelling Error Detection with Machine Learning Methods.

Please download the data set from https://www.kaggle.com/competitions/inria-bci-challenge/data and extract the data (train.zip and test.zip) to an empty directory
called "raw_data" and then store training data in "train" sub-directory while put testing data in "test" sub-directory. Please also create a "train" and a "test" directory in the root directory with "0" and "1" sub-directories in each directory.

### Project Team Members:
- Yiheng Ye, yiy291@ucsd.edu
- Crystal Ma, c4ma@ucsd.edu
- Xu Tang, xutang@ucsd.edu

### Requirements:
- python 3.9
- pandas 1.3.4
- numpy 1.21.4
- matplotlib 3.5.0
- PyTorch 1.11
- tqdm 4.64.0

### Instruction of Notebooks

Please run all of our code in a cuda-enabled envirnoment since we are using GPU for computation.

- project_preprocess_first120000.ipynb: Generates preprocessed data to train/test directory. Please run this directory before you run project_lstm.ipynb. This notebook
selects best channel to be used for training based on previous related works (see https://www.kaggle.com/competitions/inria-bci-challenge/discussion/12600) and store first 120000 data recorded for that channel from each sample.

- project_lstm.ipynb: Main notebook. This notebook takes the data generated from the previous notebook and train a simple LSTM on it. The plots generated by our experiment have already been stored in this repository (LSTMTraining.png and LSTMValidation.png) and it will also save the best model during the training process to a
new file called "best.pth".

- project_preprocess.ipynb: A notebook just generates the best channel selected from the raw data. You can use this one if you want to explore different approaches on 
this data set other than LSTM model. Please do not use the data generated by this notebook to train on the LSTM model we provide as the model requires that all samples should have the same length.

